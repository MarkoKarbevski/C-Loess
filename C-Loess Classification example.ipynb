{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dist_kern(a,b):\n",
    "    return(0.1+np.square((np.linalg.norm(a-b))))\n",
    "    \n",
    "    \n",
    "\n",
    "def CLoess_classifier(x_train, y_train, x_predict, dist_kernel = dist_kern, training = \"standard\", No_of_clusters = 10, standard_scale = True):\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_predict = np.array(x_predict)\n",
    "    \n",
    "    if len(y_train.shape)==1:\n",
    "        y_train = y_train.reshape(y_train.shape[0],1)\n",
    "    \n",
    "    #Step 1: Cluster\n",
    "    cluster_model = MiniBatchKMeans(n_clusters = No_of_clusters, batch_size = 1024, max_iter=25)\n",
    "    cluster_model.fit(x_train)\n",
    "    list_of_models = []\n",
    "    \n",
    "    #Step 2: Train for each cluster\n",
    "    predictions = np.zeros((x_predict.shape[0], y_train.shape[1]))\n",
    "    for i in range(No_of_clusters):\n",
    "\n",
    "        eval_point = cluster_model.cluster_centers_[i]\n",
    "        \n",
    "        weights=np.array([])\n",
    "        for j in range(x_train.shape[0]):\n",
    "            weights = np.append(weights, 1/dist_kernel(x_train[j,:],eval_point))\n",
    "        \n",
    "        \n",
    "        if(training ==\"sgd\"):\n",
    "            model= SGDClassifier()\n",
    "        else:\n",
    "            model= LogisticRegression(n_jobs = -1, penalty = \"none\")\n",
    "        \n",
    "        model.fit(x_train, np.ravel(y_train), sample_weight = weights) \n",
    "        list_of_models.append(model)\n",
    "        \n",
    "    #Step 3: Obtain the centroid  closest to the input point\n",
    "    closest, _ = pairwise_distances_argmin_min(x_predict, cluster_model.cluster_centers_)\n",
    "    \n",
    "    #step 4: Predict \n",
    "    for k in range(x_predict.shape[0]):\n",
    "        predictions[k,:] = list_of_models[closest[k]].predict_proba(x_predict[[k],:])[0][1]\n",
    "    \n",
    "    return(predictions, cluster_model.cluster_centers_, list_of_models)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def CLoess_regressor(x_train, y_train, x_predict, dist_kernel = dist_kern, training = \"standard\", No_of_clusters = 10, standard_scale = True):\n",
    "    \n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_predict = np.array(x_predict)\n",
    "    \n",
    "    if len(y_train.shape)==1:\n",
    "        y_train = y_train.reshape(y_train.shape[0],1)\n",
    "    \n",
    "    #Step 1: Cluster\n",
    "    \n",
    "    cluster_model = MiniBatchKMeans(n_clusters = No_of_clusters, batch_size = 1024, max_iter=25)\n",
    "    cluster_model.fit(x_train)\n",
    "    list_of_models = []\n",
    "    \n",
    "    #Step 2: Train for each cluster\n",
    "    predictions = np.zeros((x_predict.shape[0], y_train.shape[1]))\n",
    "    for i in range(No_of_clusters):\n",
    "\n",
    "        eval_point = cluster_model.cluster_centers_[i]\n",
    "        \n",
    "        weights=np.array([])\n",
    "        for j in range(x_train.shape[0]):\n",
    "            weights = np.append(weights, 1/dist_kernel(x_train[j,:],eval_point))\n",
    "        \n",
    "        \n",
    "        if(training ==\"sgd\"):\n",
    "            model= SGDRegressor()\n",
    "        else:\n",
    "            model= LinearRegression(n_jobs = -1, penalty = \"elasticnet\")\n",
    "            \n",
    "        model.fit(x_train, np.ravel(y_train), sample_weight = weights) \n",
    "        \n",
    "        list_of_models.append(model)\n",
    "        \n",
    "    #Step 3: Obtain the centroid  closest to the input point\n",
    "    closest, _ = pairwise_distances_argmin_min(x_predict, cluster_model.cluster_centers_)\n",
    "    \n",
    "    #step 4: Predict\n",
    "    for k in range(x_predict.shape[0]):\n",
    "        predictions[k,:] = list_of_models[closest[k]].predict(x_predict[[k],:])\n",
    "    \n",
    "    return(predictions, cluster_model.cluster_centers_, list_of_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Data from https://www.kaggle.com/c/santander-customer-transaction-prediction/data\n",
    "X_santander = pd.read_csv('C:\\\\Users\\\\Marko\\\\Downloads\\\\Santander\\\\santander-customer-transaction-prediction/train.csv').iloc[:,2:]\n",
    "Y_santander = pd.read_csv('C:\\\\Users\\\\Marko\\\\Downloads\\\\Santander\\\\santander-customer-transaction-prediction/train.csv').iloc[:,1]\n",
    "\n",
    "X_train, X_val, Y_train, y_val =  sk.model_selection.train_test_split(X_santander,Y_santander,test_size = 0.2, random_state=11 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression baseline ROC-AUC Score: 0.858407052268581\n",
      "Logistic regression elasticnet ROC-AUC Score: 0.8584057214415226\n",
      "XGB baseline ROC-AUC Score: 0.8301496257223091\n",
      "C-LOESS ROC-AUC Score: 0.858433264684257\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "val_predicted, centroids , list_of_models = CLoess_classifier(scaler.transform(X_train),Y_train,scaler.transform(X_val))\n",
    "\n",
    "model_baseline = LogisticRegression(penalty = 'none', solver = 'sag', max_iter=1000, n_jobs = -1)\n",
    "model_baseline.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "model_elasticnet = LogisticRegression(penalty = 'none', solver = 'sag', max_iter=1000, n_jobs = -1)\n",
    "model_elasticnet.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "model_XGB = XGBClassifier(n_jobs=-1)\n",
    "model_XGB.fit(scaler.transform(X_train),Y_train)\n",
    "\n",
    "baseline = model_baseline.predict_proba(scaler.transform(X_val))\n",
    "val_elasticnet = model_elasticnet.predict_proba(scaler.transform(X_val))\n",
    "val_XGB = model_XGB.predict_proba(scaler.transform(X_val))\n",
    "\n",
    "\n",
    "\n",
    "print('Logistic regression baseline ROC-AUC Score: {}'.format(roc_auc_score(y_val,baseline[:,1])))\n",
    "print('Logistic regression elasticnet ROC-AUC Score: {}'.format(roc_auc_score(y_val,val_elasticnet[:,1])))\n",
    "print('XGB baseline ROC-AUC Score: {}'.format(roc_auc_score(y_val,val_XGB[:,1])))\n",
    "print('C-LOESS ROC-AUC Score: {}'.format(roc_auc_score(y_val,val_predicted)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
